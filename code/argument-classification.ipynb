{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV  \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import re, string,os\n",
    "from glob import glob as gb\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from utils.functions import *\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.corpus import stopwords\n",
    "import spacy \n",
    "\n",
    "# Source: https://towardsdatascience.com/journey-to-the-center-of-multi-label-classification-384c40229bff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "project_path = '/home/ruben/Documents/GitHub/CrisisBureaucracy'\n",
    "data_path = '/media/ruben/Elements/PhD/data/hansard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load annotations from TagTog format\n",
    "# From .json to dataframe. Also loads original texts by identifier\n",
    "# Turns out that only a handfull of 'arguments' are not the full paragraph, so reverting to full paragraphs\n",
    "\n",
    "translator = {\"m_10\":\"cost\",\"m_11\":\"accountability\",\"m_12\":\"freedom\",\"m_13\":\"inefficiency\",\"m_14\":\"irrationality\",\n",
    "              \"m_15\":\"centralisation\",\"m_16\":\"power\",\"m_8\":\"neutral\",\"m_9\":\"size\"}\n",
    "\n",
    "def load_full(id_):\n",
    "    f = pd.read_csv(f'{data_path}/lemmatized_pm/uk.proc.d.{id_[:10]}.txt',sep='\\t')\n",
    "    return [list(f[f['id'] == 'uk.proc.d.' + id_]['text'])[0],list(f[f['id'] == 'uk.proc.d.' + id_]['text_lemmatized'])[0]]\n",
    "\n",
    "def combine(fn):\n",
    "    with open(fn,'r') as f:\n",
    "        c = json.load(f)\n",
    "    labels = [translator[x] for x in list(c['metas'].keys())]\n",
    "    txtn = f\"{project_path}/data/classifier/annotation-round-2/annotation-texts/\" + fn[130:].replace('.ann.json','').replace('_','-')\n",
    "    with open(ltf_[txtn],'r') as f:\n",
    "        t = f.read()\n",
    "    return [os.path.split(ltf_[txtn])[-1].replace('.txt',''),t,labels]\n",
    "\n",
    "lf = gb(f'{project_path}/data/classifier/annotation-round-2/annotation-results/*')\n",
    "ltf = gb(f'{project_path}/data/classifier/annotation-round-2/annotation-texts/*')\n",
    "ltf_ = {k.replace('_','-'):k for k in ltf}\n",
    "\n",
    "df = [combine(x) for x in lf]\n",
    "df = pd.DataFrame(df,columns=['id','text','label'])\n",
    "or_texts = [load_full(\"-\".join(x.split('-')[1:-1])) for x in df['id']]\n",
    "df['original_par'] = [x[0] for x in or_texts]\n",
    "df = df[['id','original_par','label']]\n",
    "df.columns = \"id text label\".split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 750/750 [00:13<00:00, 54.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing:\n",
    "# Remove stopwords plus frequent forms of addressing MPs (\"right hon. gentleman\") \n",
    "# POS-tag using spacy, save only adjectives, nouns and verbs (verbs are important because of \"growing bureaucracy\" etc.)\n",
    "\n",
    "stops = stopwords.words('english') + \"hon member friend gentleman gentlemen speaker right\".split(' ')\n",
    "df['text'] = [\" \".join([w.text for w in nlp(t) if w.pos_ in [\"ADJ\",\"NOUN\",\"VERB\"] and str(w.text) not in stops]) for t in tqdm(df['text'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = list(set([item for sublist in list(df['label']) for item in sublist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = df[['id','text','label']]\n",
    "for c in categories:\n",
    "    dfr[c] = [1 if c in i else 0 for i in dfr['label']]\n",
    "dfr =dfr.drop(['id','label'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "centrali. \t 0.96 0.96 0.96 0.9466 0.9466 0.9466 0.9466 0.9466 0.9466 0.9466\n",
      "power. \t 0.9466 0.9466 0.9466 0.9466 0.9333 0.9333 0.9333 0.9333 0.9333 0.9333\n",
      "cost. \t 0.8666 0.8666 0.8666 0.8666 0.8666 0.8666 0.8666 0.8666 0.8666 0.8533\n",
      "irration. \t 0.9866 0.9866 0.9866 0.9866 0.9866 0.9866 0.9733 0.9733 0.9733 0.9733\n",
      "size. \t 0.7066 0.68 0.7333 0.7333 0.7066 0.68 0.7466 0.72 0.7333 0.6933\n",
      "accounta. \t 0.9333 0.9333 0.9333 0.9333 0.9333 0.9333 0.9333 0.92 0.92 0.92\n",
      "ineffici. \t 0.84 0.84 0.84 0.84 0.84 0.84 0.84 0.84 0.84 0.8266\n",
      "freedom. \t 0.92 0.92 0.9066 0.9066 0.9066 0.9066 0.9066 0.9066 0.9066 0.9066\n",
      "neutral. \t 0.7866 0.7866 0.7866 0.7733 0.7733 0.7733 0.7733 0.7733 0.7733 0.7733\n"
     ]
    }
   ],
   "source": [
    "# Cross-Validation with a pipeline. To do: GridSearch (although no huge differences in earlier tests)\n",
    "# Using OneVsRestClassifier, so basically making a separate classifier for every label.\n",
    "\n",
    "NB_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,4), max_features=10000)),\n",
    "                ('clf', OneVsRestClassifier(MultinomialNB(\n",
    "                    fit_prior=True, class_prior=None))),\n",
    "                ])\n",
    "for category in categories:\n",
    "    scores = cross_validate(NB_pipeline, dfr['text'], dfr[category], scoring=['accuracy'], cv=10, return_train_score=False)\n",
    "    print(category[:8] + '.','\\t',\" \".join([str(x)[:6] for x in scores['test_accuracy']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy =  0.11290322580645161\n"
     ]
    }
   ],
   "source": [
    "# initialize binary relevance multi-label classifier\n",
    "# with a gaussian naive bayes base classifier\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=10000)\n",
    "tfidf_vect.fit(dfr['text'])\n",
    "train,test = train_test_split(dfr, random_state=42, test_size=0.33, shuffle=True)\n",
    "\n",
    "xtrain_tfidf =  tfidf_vect.transform(train.text)\n",
    "xvalid_tfidf =  tfidf_vect.transform(test.text)\n",
    "\n",
    "classifier = BinaryRelevance(GaussianNB())\n",
    "# train\n",
    "classifier.fit(xtrain_tfidf, train.drop(labels = ['text'], axis=1))\n",
    "# predict\n",
    "predictions = classifier.predict(xvalid_tfidf)\n",
    "# accuracy\n",
    "print(\"Accuracy = \",accuracy_score(test.drop(labels = ['text'], axis=1),predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy =  0.27419354838709675\n\n\n"
     ]
    }
   ],
   "source": [
    "# using classifier chains\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# initialize classifier chains multi-label classifier\n",
    "classifier = ClassifierChain(LogisticRegression())\n",
    "# Training logistic regression model on train data\n",
    "classifier.fit(xtrain_tfidf, train.drop(labels = ['text'], axis=1))\n",
    "# predict\n",
    "predictions = classifier.predict(xvalid_tfidf)\n",
    "# accuracy\n",
    "print(\"Accuracy = \",accuracy_score(test.drop(labels = ['text'], axis=1),predictions))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy =  0.2056451612903226\n\n\n"
     ]
    }
   ],
   "source": [
    "# using Label Powerset\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "# initialize label powerset multi-label classifier\n",
    "classifier = LabelPowerset(LogisticRegression())\n",
    "# train\n",
    "# Training logistic regression model on train data\n",
    "classifier.fit(xtrain_tfidf, train.drop(labels = ['text'], axis=1))\n",
    "# predict\n",
    "predictions = classifier.predict(xvalid_tfidf)\n",
    "# accuracy\n",
    "print(\"Accuracy = \",accuracy_score(test.drop(labels = ['text'], axis=1),predictions))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy =  0.13709677419354838\n\n\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.adapt import MLkNN\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "classifier_new = MLkNN(k=10)\n",
    "# Note that this classifier can throw up errors when handling sparse matrices.\n",
    "x_train = lil_matrix(xtrain_tfidf).toarray()\n",
    "y_train = lil_matrix(train.drop(labels = ['text'], axis=1)).toarray()\n",
    "x_test = lil_matrix(xvalid_tfidf).toarray()\n",
    "# train\n",
    "classifier_new.fit(x_train, y_train)\n",
    "# predict\n",
    "predictions_new = classifier_new.predict(x_test)\n",
    "# accuracy\n",
    "print(\"Accuracy = \",accuracy_score(test.drop(labels = ['text'], axis=1),predictions_new))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1000/1000 [00:21<00:00, 46.90it/s]\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# Making new predictions on all the data (everything below is testing)\n",
    "##\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=10000)\n",
    "tfidf_vect.fit(dfr['text'])\n",
    "\n",
    "# import all\n",
    "new_df = pd.read_csv('~/Documents/GitHub/CrisisBureaucracy/data/classifier/bureaucracy-sentences-full.tsv',sep='\\t').dropna()\n",
    "new_df.columns = \"id text\".split(' ')\n",
    "new_df = new_df.sample(1000).reset_index(drop=True)\n",
    "\n",
    "# Preprocessing\n",
    "stops = stopwords.words('english') + \"hon member friend gentleman gentlemen speaker right\".split(' ')\n",
    "new_df['text'] = [\" \".join([w.text for w in nlp(t) if w.pos_ in [\"ADJ\",\"NOUN\",\"VERB\"] and str(w.text) not in stops]) for t in tqdm(new_df['text'])]\n",
    "new_docs_tfidf = tfidf_vect.transform(new_df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in ['accountability','cost','freedom','size']:\n",
    "    model = OneVsRestClassifier(MultinomialNB(fit_prior=True, class_prior=None)).fit(tfidf_vect.fit_transform(dfr.text), dfr[cat])\n",
    "    predictions = model.predict_proba(new_docs_tfidf)\n",
    "    new_df[cat] = [x[1] for x in predictions]"
   ]
  }
 ]
}