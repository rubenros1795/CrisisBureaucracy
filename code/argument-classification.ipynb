{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split, RandomizedSearchCV,cross_val_score,cross_validate  \n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report,f1_score,roc_auc_score,average_precision_score,average_precision_score,recall_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import re, string,os\n",
    "from glob import glob as gb\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from utils.functions import *\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.corpus import stopwords\n",
    "import spacy \n",
    "\n",
    "# Source: https://towardsdatascience.com/journey-to-the-center-of-multi-label-classification-384c40229bff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "project_path = '/home/ruben/Documents/GitHub/CrisisBureaucracy'\n",
    "data_path = '/media/ruben/Elements/PhD/data/hansard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load annotations from TagTog format\n",
    "# From .json to dataframe. Also loads original texts by identifier\n",
    "# Turns out that only a handfull of 'arguments' are not the full paragraph, so reverting to full paragraphs\n",
    "\n",
    "translator = {\"m_10\":\"cost\",\"m_11\":\"accountability\",\"m_12\":\"freedom\",\"m_13\":\"inefficiency\",\"m_14\":\"irrationality\",\n",
    "              \"m_15\":\"centralisation\",\"m_16\":\"power\",\"m_8\":\"neutral\",\"m_9\":\"size\"}\n",
    "\n",
    "def load_full(id_):\n",
    "    f = pd.read_csv(f'{data_path}/lemmatized_pm/uk.proc.d.{id_[:10]}.txt',sep='\\t')\n",
    "    return [list(f[f['id'] == 'uk.proc.d.' + id_]['text'])[0],list(f[f['id'] == 'uk.proc.d.' + id_]['text_lemmatized'])[0]]\n",
    "\n",
    "def combine(fn):\n",
    "    with open(fn,'r') as f:\n",
    "        c = json.load(f)\n",
    "    labels = [translator[x] for x in list(c['metas'].keys())]\n",
    "    txtn = f\"{project_path}/data/classifier/annotation-round-2/annotation-texts/\" + fn[130:].replace('.ann.json','').replace('_','-')\n",
    "    with open(ltf_[txtn],'r') as f:\n",
    "        t = f.read()\n",
    "    return [os.path.split(ltf_[txtn])[-1].replace('.txt',''),t,labels]\n",
    "\n",
    "lf = gb(f'{project_path}/data/classifier/annotation-round-2/annotation-results/*')\n",
    "ltf = gb(f'{project_path}/data/classifier/annotation-round-2/annotation-texts/*')\n",
    "ltf_ = {k.replace('_','-'):k for k in ltf}\n",
    "\n",
    "df = pd.DataFrame([combine(x) for x in lf],columns=['id','text','label'])\n",
    "df['text'] = [load_full(\"-\".join(x.split('-')[1:-1]))[0] for x in df['id']]\n",
    "df = df[['id','text','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing:\n",
    "# Remove stopwords plus frequent forms of addressing MPs (\"right hon. gentleman\") \n",
    "# POS-tag using spacy, save only adjectives, nouns and verbs (verbs are important because of \"growing bureaucracy\" etc.)\n",
    "\n",
    "stops = stopwords.words('english') + \"hon member friend gentleman gentlemen speaker right\".split(' ')\n",
    "df['text'] = [\" \".join([w.text for w in nlp(t) if w.pos_ in [\"ADJ\",\"NOUN\",\"VERB\"] and str(w.text) not in stops]) for t in tqdm(df['text'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = [x[0] for x in df['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = list(set([item for sublist in list(df['label']) for item in sublist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = df[['id','text','label']]\n",
    "for c in categories:\n",
    "    dfr[c] = [1 if c in i else 0 for i in dfr['label']]\n",
    "dfr =dfr.drop(['id','label'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "centrali. \t 0.96 0.96 0.96 0.9466 0.9466 0.9466 0.9466 0.9466 0.9466 0.9466\n",
      "power. \t 0.9466 0.9466 0.9466 0.9466 0.9333 0.9333 0.9333 0.9333 0.9333 0.9333\n",
      "cost. \t 0.8666 0.8666 0.8666 0.8666 0.8666 0.8666 0.8666 0.8666 0.8666 0.8533\n",
      "irration. \t 0.9866 0.9866 0.9866 0.9866 0.9866 0.9866 0.9733 0.9733 0.9733 0.9733\n",
      "size. \t 0.7066 0.68 0.7333 0.7333 0.7066 0.68 0.7466 0.72 0.7333 0.6933\n",
      "accounta. \t 0.9333 0.9333 0.9333 0.9333 0.9333 0.9333 0.9333 0.92 0.92 0.92\n",
      "ineffici. \t 0.84 0.84 0.84 0.84 0.84 0.84 0.84 0.84 0.84 0.8266\n",
      "freedom. \t 0.92 0.92 0.9066 0.9066 0.9066 0.9066 0.9066 0.9066 0.9066 0.9066\n",
      "neutral. \t 0.7866 0.7866 0.7866 0.7733 0.7733 0.7733 0.7733 0.7733 0.7733 0.7733\n"
     ]
    }
   ],
   "source": [
    "# Cross-Validation with a pipeline. To do: GridSearch (although no huge differences in earlier tests)\n",
    "# Using OneVsRestClassifier, so basically making a separate classifier for every label.\n",
    "\n",
    "NB_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,4), max_features=10000)),\n",
    "                ('clf', OneVsRestClassifier(naive_bayes.MultinomialNB(\n",
    "                    fit_prior=True, class_prior=None))),\n",
    "                ])\n",
    "for category in categories:\n",
    "    scores = cross_validate(NB_pipeline, dfr['text'], dfr[category], scoring=['accuracy'], cv=10, return_train_score=False)\n",
    "    print(category[:8] + '.','\\t',\" \".join([str(x)[:6] for x in scores['test_accuracy']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy =  0.11290322580645161\n"
     ]
    }
   ],
   "source": [
    "# initialize binary relevance multi-label classifier\n",
    "# with a gaussian naive bayes base classifier\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=10000)\n",
    "tfidf_vect.fit(dfr['text'])\n",
    "train,test = train_test_split(dfr, random_state=42, test_size=0.33, shuffle=True)\n",
    "\n",
    "xtrain_tfidf =  tfidf_vect.transform(train.text)\n",
    "xvalid_tfidf =  tfidf_vect.transform(test.text)\n",
    "\n",
    "classifier = BinaryRelevance(GaussianNB())\n",
    "# train\n",
    "classifier.fit(xtrain_tfidf, train.drop(labels = ['text'], axis=1))\n",
    "# predict\n",
    "predictions = classifier.predict(xvalid_tfidf)\n",
    "# accuracy\n",
    "print(\"Accuracy = \",accuracy_score(test.drop(labels = ['text'], axis=1),predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy =  0.27419354838709675\n\n\n"
     ]
    }
   ],
   "source": [
    "# using classifier chains\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# initialize classifier chains multi-label classifier\n",
    "classifier = ClassifierChain(LogisticRegression())\n",
    "# Training logistic regression model on train data\n",
    "classifier.fit(xtrain_tfidf, train.drop(labels = ['text'], axis=1))\n",
    "# predict\n",
    "predictions = classifier.predict(xvalid_tfidf)\n",
    "# accuracy\n",
    "print(\"Accuracy = \",accuracy_score(test.drop(labels = ['text'], axis=1),predictions))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy =  0.2056451612903226\n\n\n"
     ]
    }
   ],
   "source": [
    "# using Label Powerset\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "# initialize label powerset multi-label classifier\n",
    "classifier = LabelPowerset(LogisticRegression())\n",
    "# train\n",
    "# Training logistic regression model on train data\n",
    "classifier.fit(xtrain_tfidf, train.drop(labels = ['text'], axis=1))\n",
    "# predict\n",
    "predictions = classifier.predict(xvalid_tfidf)\n",
    "# accuracy\n",
    "print(\"Accuracy = \",accuracy_score(test.drop(labels = ['text'], axis=1),predictions))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy =  0.13709677419354838\n\n\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.adapt import MLkNN\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "classifier_new = MLkNN(k=10)\n",
    "# Note that this classifier can throw up errors when handling sparse matrices.\n",
    "x_train = lil_matrix(xtrain_tfidf).toarray()\n",
    "y_train = lil_matrix(train.drop(labels = ['text'], axis=1)).toarray()\n",
    "x_test = lil_matrix(xvalid_tfidf).toarray()\n",
    "# train\n",
    "classifier_new.fit(x_train, y_train)\n",
    "# predict\n",
    "predictions_new = classifier_new.predict(x_test)\n",
    "# accuracy\n",
    "print(\"Accuracy = \",accuracy_score(test.drop(labels = ['text'], axis=1),predictions_new))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine categories\n",
    "\n",
    "## irrationality -> inefficiency\n",
    "## power -> size\n",
    "## freedom -> accountability\n",
    "## centralisation -> size\n",
    "\n",
    "\n",
    "dfr['inefficiency'] = dfr['inefficiency'] + dfr['irrationality']\n",
    "dfr['size'] = dfr['size'] + dfr['power'] + dfr['centralisation']\n",
    "#dfr['accountability'] = dfr['accountability'] + dfr['freedom']\n",
    "\n",
    "dfr = dfr.drop(['irrationality','power','centralisation','freedom'],axis=1)\n",
    "\n",
    "\n",
    "dfr = dfr.replace(2,1)\n",
    "dfr = dfr.replace(3,1)\n",
    "dfr = dfr.replace(4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using BERT for feature extraction\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from xgboost import XGBClassifier\n",
    "import swifter \n",
    "\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Pandas Apply: 100%|██████████| 750/750 [01:16<00:00,  9.86it/s]\n"
     ]
    }
   ],
   "source": [
    "vects = dfr['text'].swifter.apply(model.encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr['sentence-bert'] = vects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_embeddings(embeddings):\n",
    "    import numpy as np\n",
    "    return np.vstack(embeddings.values)\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    ('bag of ngrams', TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=10000), 'text'),\n",
    "    # Lambda functions cannot be pickled\n",
    "    ('sentence bert', FunctionTransformer(stack_embeddings), 'sentence-bert')],remainder='passthrough')\n",
    "\n",
    "# lm = LogisticRegression()\n",
    "xgb = XGBClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline = Pipeline([('transformer', ct), ('classifier', xgb)])\n",
    "#pipeline = Pipeline([('transformer', ct), ('classifier', LogisticRegression())])\n",
    "pipeline = Pipeline([('transformer', ct), ('classifier', naive_bayes.MultinomialNB)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "fit() missing 1 required positional argument: 'y'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-f6f980d2357e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_c\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "for category in \"accountability inefficiency neutral size cost\".split(' '):\n",
    "    df_c = dfr.copy()\n",
    "    y,X = df_c.pop(category),df_c\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.5, random_state=42,stratify=y)\n",
    "    model = pipeline.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(category)\n",
    "    print(metrics.classification_report(y_test,y_pred))\n",
    "    print('------------------------------_')\n",
    "    #scores = cross_validate(pipeline, dfr['text'], dfr[category], scoring=['accuracy'], cv=10, return_train_score=False)\n",
    "    #print(category[:8] + '.','\\t',\" \".join([str(x)[:6] for x in scores['test_accuracy']]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1000/1000 [00:21<00:00, 46.90it/s]\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# Making new predictions on all the data (everything below is testing)\n",
    "##\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=10000)\n",
    "tfidf_vect.fit(dfr['text'])\n",
    "\n",
    "# import all\n",
    "new_df = pd.read_csv('~/Documents/GitHub/CrisisBureaucracy/data/classifier/bureaucracy-sentences-full.tsv',sep='\\t').dropna()\n",
    "new_df.columns = \"id text\".split(' ')\n",
    "new_df = new_df.sample(1000).reset_index(drop=True)\n",
    "\n",
    "# Preprocessing\n",
    "stops = stopwords.words('english') + \"hon member friend gentleman gentlemen speaker right\".split(' ')\n",
    "new_df['text'] = [\" \".join([w.text for w in nlp(t) if w.pos_ in [\"ADJ\",\"NOUN\",\"VERB\"] and str(w.text) not in stops]) for t in tqdm(new_df['text'])]\n",
    "new_docs_tfidf = tfidf_vect.transform(new_df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in ['accountability','cost','freedom','size']:\n",
    "    model = OneVsRestClassifier(MultinomialNB(fit_prior=True, class_prior=None)).fit(tfidf_vect.fit_transform(dfr.text), dfr[cat])\n",
    "    predictions = model.predict_proba(new_docs_tfidf)\n",
    "    new_df[cat] = [x[1] for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}