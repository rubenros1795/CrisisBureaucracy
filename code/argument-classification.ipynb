{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV  # or GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import re, string,os\n",
    "from glob import glob as gb\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from utils.functions import *\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.corpus import stopwords\n",
    "stops = stopwords.words('english') + [\"hon\",\"member\",\"right\",\"friend\",\"mr\",'hon.','make','say','great']\n",
    "\n",
    "from classification import *\n",
    "import spacy \n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# First test: https://www.analyticsvidhya.com/blog/2018/04/a-comprehensive-guide-to-understand-and-implement-text-classification-in-python/\n",
    "# Word2vec: http://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 640/640 [00:09<00:00, 64.87it/s]\n"
     ]
    }
   ],
   "source": [
    "## Import annotated data\n",
    "annotations = pd.read_csv('~/Documents/GitHub/CrisisBureaucracy/data/classifier/annotated-arguments-bureaucracy.csv')\n",
    "annotations['metadata'] = ''\n",
    "\n",
    "refdata = pd.read_csv('~/Documents/GitHub/CrisisBureaucracy/data/classifier/training_data_full.csv',sep='\\t')\n",
    "refdata['id-ann'] = [x + 594 for x in refdata.index]\n",
    "\n",
    "for c,i in enumerate(annotations['id']):\n",
    "    annotations['metadata'][c] = str(refdata[refdata['id-ann'] == i].reset_index(drop=True)['id'][0])\n",
    "\n",
    "annotations['text'] = utils.preprocess_(annotations['text'])\n",
    "annotations = annotations[[\"id\",\"label\",\"text\"]]\n",
    "annotations['text'] = [\" \".join([w.text for w in nlp(t) if w.pos_ in [\"ADJ\",\"NOUN\"] and w.text not in stops]) for t in tqdm(annotations['text'])]\n",
    "\n",
    "labels = {1:\"neutral\",2:\"inefficient\",3:\"powerful/large\",4:\"centralization\",5:\"freedom\",6:\"expensive\",7:\"anti-democratic\"}\n",
    "annotations['label'] = annotations['label'].astype(str)\n",
    "annotations['label'] = [labels[int(x)] for x in annotations['label']]\n",
    "\n",
    "df = annotations.drop_duplicates('text')\n",
    "df = df[df['label'] != 'neutral'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      freedom inefficient anti-democratic   expensive powerful/large  \\\n",
       "0     freedom  government      democratic        cost     government   \n",
       "1     citizen       board      parliament  government         people   \n",
       "2      people    minister           elect       money        service   \n",
       "3       house       small       democracy     service          local   \n",
       "4  individual        case       executive  commission      authority   \n",
       "\n",
       "  centralization  \n",
       "0       industry  \n",
       "1          state  \n",
       "2         policy  \n",
       "3     government  \n",
       "4    nationalise  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>freedom</th>\n      <th>inefficient</th>\n      <th>anti-democratic</th>\n      <th>expensive</th>\n      <th>powerful/large</th>\n      <th>centralization</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>freedom</td>\n      <td>government</td>\n      <td>democratic</td>\n      <td>cost</td>\n      <td>government</td>\n      <td>industry</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>citizen</td>\n      <td>board</td>\n      <td>parliament</td>\n      <td>government</td>\n      <td>people</td>\n      <td>state</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>people</td>\n      <td>minister</td>\n      <td>elect</td>\n      <td>money</td>\n      <td>service</td>\n      <td>policy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>house</td>\n      <td>small</td>\n      <td>democracy</td>\n      <td>service</td>\n      <td>local</td>\n      <td>government</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>individual</td>\n      <td>case</td>\n      <td>executive</td>\n      <td>commission</td>\n      <td>authority</td>\n      <td>nationalise</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "# Inspect Category TF-IDF terms\n",
    "tfidfo, docterms = tfidf.get_docterms(df,\"text\")\n",
    "tt = tfidf.get_topterms(tfidfo,docterms,df,'label')\n",
    "tt.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['label'] = [\"argument\" if x != \"neutral\" else \"non-argument\" for x in df['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model train function\n",
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid):\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    return metrics.accuracy_score(predictions, valid_y)\n",
    "\n",
    "# Vectorize\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=8000)\n",
    "tfidf_vect.fit(df['text'])\n",
    "\n",
    "# Split Test/Train sets and vectorize\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(df['text'], df['label'], test_size=0.333)\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf =  tfidf_vect.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NB, Vectors:  0.2982456140350877\n",
      "SVM, Vectors:  0.2894736842105263\n",
      "Random Forest, Vectors:  0.2894736842105263\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Naive Bayes on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print(\"NB, Vectors: \", accuracy)\n",
    "\n",
    "# Evaluate SVM on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(svm.SVC(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print(\"SVM, Vectors: \", accuracy)\n",
    "\n",
    "# Evaluate RF on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(RandomForestClassifier(n_estimators=100), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print(\"Random Forest, Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.35714286, 0.35714286, 0.35714286, 0.28571429, 0.28571429,\n",
       "       0.35714286, 0.35714286, 0.35714286, 0.35714286, 0.35714286,\n",
       "       0.28571429, 0.28571429, 0.28571429, 0.07142857, 0.28571429,\n",
       "       0.28571429, 0.28571429, 0.30769231, 0.23076923, 0.30769231,\n",
       "       0.23076923, 0.30769231, 0.30769231, 0.23076923, 0.30769231])"
      ]
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "# Use Cross-Validation\n",
    "clf = make_pipeline(tfidf_vect, naive_bayes.MultinomialNB())\n",
    "scores = cross_validate(clf, df['text'], df['label'], scoring=['accuracy'], cv=25, return_train_score=False)\n",
    "scores['test_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfidfEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim = len(word2vec.values())\n",
    "\n",
    "    def fit(self, X):\n",
    "        tfidf = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,2), max_features=2500)\n",
    "        tfidf.fit(X)\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(lambda: max_idf,[(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([np.mean([self.word2vec[w] * self.word2weight[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0) for words in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format(\"~/Documents/GitHub/CrisisBureaucracy/results/w2v-models/model-single-sample.bin\",binary=True)\n",
    "w2v = dict(zip(model.wv.index2word, model.wv.syn0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SVM, Vectors:  0.270935960591133\nRandom Forest, Vectors:  0.2315270935960591\n"
     ]
    }
   ],
   "source": [
    "# Model train function\n",
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid):\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    return metrics.accuracy_score(predictions, valid_y)\n",
    "\n",
    "# Vectorize\n",
    "tfidf_vect = TfidfEmbeddingVectorizer(w2v)\n",
    "tfidf_vect.fit(df['text'])\n",
    "\n",
    "# Split Test/Train sets and vectorize\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(df['text'], df['label'], test_size=0.6)\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf =  tfidf_vect.transform(valid_x)\n",
    "\n",
    "# Evaluate SVM on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(svm.SVC(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print(\"SVM, Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob as gb\n",
    "import json \n",
    "import pandas as pd\n",
    "\n",
    "translator = {\n",
    "    \"m_10\":\"cost\",\n",
    "    \"m_11\":\"accountability\",\n",
    "    \"m_12\":\"freedom\",\n",
    "    \"m_13\":\"inefficiency\",\n",
    "    \"m_14\":\"irrationality\",\n",
    "    \"m_15\":\"centralisation\",\n",
    "    \"m_16\":\"power\",\n",
    "    \"m_8\":\"neutral\",\n",
    "    \"m_9\":\"size\"\n",
    "}\n",
    "\n",
    "lf = gb('/home/ruben/Documents/GitHub/CrisisBureaucracy/data/classifier/annotation-round-2/annotation-results/*')\n",
    "ltf = gb('/home/ruben/Documents/GitHub/CrisisBureaucracy/data/classifier/annotation-round-2/annotation-texts/*')\n",
    "ltf_ = {k.replace('_','-'):k for k in ltf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_labels(fn):\n",
    "    try:\n",
    "        with open(fn,'r') as f:\n",
    "            c = json.load(f)\n",
    "        labels = [translator[x] for x in list(c['metas'].keys())]\n",
    "\n",
    "        txtn = fn[130:].replace('.ann.json','').replace('_','-')\n",
    "        txtn = \"/home/ruben/Documents/GitHub/CrisisBureaucracy/data/classifier/annotation-round-2/annotation-texts/\" + txtn\n",
    "\n",
    "        with open(ltf_[txtn],'r') as f:\n",
    "            t = f.read()\n",
    "        return [os.path.split(ltf_[txtn])[-1].replace('.txt',''),t,labels]\n",
    "    except:\n",
    "        print(e)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = [load_text_labels(x) for x in lf]\n",
    "d = []\n",
    "\n",
    "for x in df:\n",
    "    for l in x[2]:\n",
    "        d.append([x[0],x[1],l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 342/342 [00:05<00:00, 60.40it/s]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(d,columns=['id','text','label'])\n",
    "df['text'] = utils.preprocess_(df['text'])\n",
    "df['text'] = [\" \".join([w.text for w in nlp(t) if w.pos_ in [\"ADJ\",\"NOUN\"] and w.text not in stops]) for t in tqdm(df['text'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect Category TF-IDF terms\n",
    "tfidfo, docterms = tfidf.get_docterms(df,\"text\")\n",
    "tt = tfidf.get_topterms(tfidfo,docterms,df,'label')\n",
    "tt = tt.head(15)\n",
    "tt.head(15)\n",
    "ttm = tt.melt()\n",
    "unique_words = {cat:[w for w in tt[cat] if w not in set(ttm[ttm['variable'] != cat]['value'])] for cat in tt.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                  id  \\\n",
       "0             10659-1983-07-18.15.1.4.7-conservative   \n",
       "1                 10327-1981-07-30.10.17.28.2-labour   \n",
       "2                  18728-1972-08-03.15.1.11.8-labour   \n",
       "3             18622-1967-02-01.8.2.88.1-conservative   \n",
       "4                   17461-1982-11-23.8.1.72.1-labour   \n",
       "..                                               ...   \n",
       "337        21715-1968-01-29.17.1.199.12-conservative   \n",
       "338        21715-1968-01-29.17.1.199.12-conservative   \n",
       "339  21872-1967-05-12.7.1.4.20-ulster_unionist_party   \n",
       "340  21872-1967-05-12.7.1.4.20-ulster_unionist_party   \n",
       "341           10362-1985-03-22.3.1.17.5-conservative   \n",
       "\n",
       "                                                  text           label  \n",
       "0    new regime per cent reduction dlo work force m...            size  \n",
       "1    line new clause system planning permission cou...            size  \n",
       "2    modern world talk devolution responsibility pl...  accountability  \n",
       "3    order deputy speaker increase loan contain sup...    inefficiency  \n",
       "4    gentleman main objective reform effective expa...    inefficiency  \n",
       "..                                                 ...             ...  \n",
       "337  general proposition growth bureaucracy bad num...            size  \n",
       "338  general proposition growth bureaucracy bad num...            cost  \n",
       "339  important part british constitution many year ...         freedom  \n",
       "340  important part british constitution many year ...    inefficiency  \n",
       "341  export subsidy state development aid country g...         neutral  \n",
       "\n",
       "[342 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10659-1983-07-18.15.1.4.7-conservative</td>\n      <td>new regime per cent reduction dlo work force m...</td>\n      <td>size</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10327-1981-07-30.10.17.28.2-labour</td>\n      <td>line new clause system planning permission cou...</td>\n      <td>size</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>18728-1972-08-03.15.1.11.8-labour</td>\n      <td>modern world talk devolution responsibility pl...</td>\n      <td>accountability</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>18622-1967-02-01.8.2.88.1-conservative</td>\n      <td>order deputy speaker increase loan contain sup...</td>\n      <td>inefficiency</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17461-1982-11-23.8.1.72.1-labour</td>\n      <td>gentleman main objective reform effective expa...</td>\n      <td>inefficiency</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>337</th>\n      <td>21715-1968-01-29.17.1.199.12-conservative</td>\n      <td>general proposition growth bureaucracy bad num...</td>\n      <td>size</td>\n    </tr>\n    <tr>\n      <th>338</th>\n      <td>21715-1968-01-29.17.1.199.12-conservative</td>\n      <td>general proposition growth bureaucracy bad num...</td>\n      <td>cost</td>\n    </tr>\n    <tr>\n      <th>339</th>\n      <td>21872-1967-05-12.7.1.4.20-ulster_unionist_party</td>\n      <td>important part british constitution many year ...</td>\n      <td>freedom</td>\n    </tr>\n    <tr>\n      <th>340</th>\n      <td>21872-1967-05-12.7.1.4.20-ulster_unionist_party</td>\n      <td>important part british constitution many year ...</td>\n      <td>inefficiency</td>\n    </tr>\n    <tr>\n      <th>341</th>\n      <td>10362-1985-03-22.3.1.17.5-conservative</td>\n      <td>export subsidy state development aid country g...</td>\n      <td>neutral</td>\n    </tr>\n  </tbody>\n</table>\n<p>342 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}