{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split, RandomizedSearchCV,cross_val_score,cross_validate  \n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report,f1_score,roc_auc_score,average_precision_score,average_precision_score,recall_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import re, string,os\n",
    "from glob import glob as gb\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from utils.functions import *\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.corpus import stopwords\n",
    "import spacy \n",
    "\n",
    "# Source: https://towardsdatascience.com/journey-to-the-center-of-multi-label-classification-384c40229bff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "project_path = '/home/ruben/Documents/GitHub/CrisisBureaucracy'\n",
    "data_path = '/media/ruben/Elements/PhD/data/hansard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load annotations from TagTog format\n",
    "# From .json to dataframe. Also loads original texts by identifier\n",
    "# Turns out that only a handfull of 'arguments' are not the full paragraph, so reverting to full paragraphs\n",
    "\n",
    "translator = {\"m_10\":\"cost\",\"m_11\":\"accountability\",\"m_12\":\"freedom\",\"m_13\":\"inefficiency\",\"m_14\":\"irrationality\",\n",
    "              \"m_15\":\"centralisation\",\"m_16\":\"power\",\"m_8\":\"neutral\",\"m_9\":\"size\"}\n",
    "\n",
    "def load_full(id_):\n",
    "    f = pd.read_csv(f'{data_path}/lemmatized_pm/uk.proc.d.{id_[:10]}.txt',sep='\\t')\n",
    "    return [list(f[f['id'] == 'uk.proc.d.' + id_]['text'])[0],list(f[f['id'] == 'uk.proc.d.' + id_]['text_lemmatized'])[0]]\n",
    "\n",
    "def combine(fn):\n",
    "    with open(fn,'r') as f:\n",
    "        c = json.load(f)\n",
    "    labels = [translator[x] for x in list(c['metas'].keys())]\n",
    "    txtn = f\"{project_path}/data/classifier/annotation-round-2/annotation-texts/\" + fn[130:].replace('.ann.json','').replace('_','-')\n",
    "    with open(ltf_[txtn],'r') as f:\n",
    "        t = f.read()\n",
    "    return [os.path.split(ltf_[txtn])[-1].replace('.txt',''),t,labels]\n",
    "\n",
    "lf = gb(f'{project_path}/data/classifier/annotation-round-2/annotation-results/*')\n",
    "ltf = gb(f'{project_path}/data/classifier/annotation-round-2/annotation-texts/*')\n",
    "ltf_ = {k.replace('_','-'):k for k in ltf}\n",
    "\n",
    "df = pd.DataFrame([combine(x) for x in lf],columns=['id','text','label'])\n",
    "df['text'] = [load_full(\"-\".join(x.split('-')[1:-1]))[0] for x in df['id']]\n",
    "df = df[['id','text','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 750/750 [00:14<00:00, 50.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing:\n",
    "# Remove stopwords plus frequent forms of addressing MPs (\"right hon. gentleman\") \n",
    "# POS-tag using spacy, save only adjectives, nouns and verbs (verbs are important because of \"growing bureaucracy\" etc.)\n",
    "\n",
    "stops = stopwords.words('english') + \"hon member friend gentleman gentlemen speaker right\".split(' ')\n",
    "df['text'] = [\" \".join([w.text for w in nlp(t) if w.pos_ in [\"ADJ\",\"NOUN\",\"VERB\"] and str(w.text) not in stops]) for t in tqdm(df['text'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = list(set([item for sublist in list(df['label']) for item in sublist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = df[['id','text','label']]\n",
    "for c in categories:\n",
    "    dfr[c] = [1 if c in i else 0 for i in dfr['label']]\n",
    "dfr =dfr.drop(['id','label'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "centrali. \t 0.96 0.96 0.96 0.9466 0.9466 0.9466 0.9466 0.9466 0.9466 0.9466\n",
      "power. \t 0.9466 0.9466 0.9466 0.9466 0.9333 0.9333 0.9333 0.9333 0.9333 0.9333\n",
      "cost. \t 0.8666 0.8666 0.8666 0.8666 0.8666 0.8666 0.8666 0.8666 0.8666 0.8533\n",
      "irration. \t 0.9866 0.9866 0.9866 0.9866 0.9866 0.9866 0.9733 0.9733 0.9733 0.9733\n",
      "size. \t 0.7066 0.68 0.7333 0.7333 0.7066 0.68 0.7466 0.72 0.7333 0.6933\n",
      "accounta. \t 0.9333 0.9333 0.9333 0.9333 0.9333 0.9333 0.9333 0.92 0.92 0.92\n",
      "ineffici. \t 0.84 0.84 0.84 0.84 0.84 0.84 0.84 0.84 0.84 0.8266\n",
      "freedom. \t 0.92 0.92 0.9066 0.9066 0.9066 0.9066 0.9066 0.9066 0.9066 0.9066\n",
      "neutral. \t 0.7866 0.7866 0.7866 0.7733 0.7733 0.7733 0.7733 0.7733 0.7733 0.7733\n"
     ]
    }
   ],
   "source": [
    "# Cross-Validation with a pipeline. To do: GridSearch (although no huge differences in earlier tests)\n",
    "# Using OneVsRestClassifier, so basically making a separate classifier for every label.\n",
    "\n",
    "NB_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,4), max_features=10000)),\n",
    "                ('clf', OneVsRestClassifier(naive_bayes.MultinomialNB(\n",
    "                    fit_prior=True, class_prior=None))),\n",
    "                ])\n",
    "for category in categories:\n",
    "    scores = cross_validate(NB_pipeline, dfr['text'], dfr[category], scoring=['accuracy'], cv=10, return_train_score=False)\n",
    "    print(category[:8] + '.','\\t',\" \".join([str(x)[:6] for x in scores['test_accuracy']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy =  0.11290322580645161\n"
     ]
    }
   ],
   "source": [
    "# initialize binary relevance multi-label classifier\n",
    "# with a gaussian naive bayes base classifier\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=10000)\n",
    "tfidf_vect.fit(dfr['text'])\n",
    "train,test = train_test_split(dfr, random_state=42, test_size=0.33, shuffle=True)\n",
    "\n",
    "xtrain_tfidf =  tfidf_vect.transform(train.text)\n",
    "xvalid_tfidf =  tfidf_vect.transform(test.text)\n",
    "\n",
    "classifier = BinaryRelevance(GaussianNB())\n",
    "# train\n",
    "classifier.fit(xtrain_tfidf, train.drop(labels = ['text'], axis=1))\n",
    "# predict\n",
    "predictions = classifier.predict(xvalid_tfidf)\n",
    "# accuracy\n",
    "print(\"Accuracy = \",accuracy_score(test.drop(labels = ['text'], axis=1),predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy =  0.27419354838709675\n\n\n"
     ]
    }
   ],
   "source": [
    "# using classifier chains\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# initialize classifier chains multi-label classifier\n",
    "classifier = ClassifierChain(LogisticRegression())\n",
    "# Training logistic regression model on train data\n",
    "classifier.fit(xtrain_tfidf, train.drop(labels = ['text'], axis=1))\n",
    "# predict\n",
    "predictions = classifier.predict(xvalid_tfidf)\n",
    "# accuracy\n",
    "print(\"Accuracy = \",accuracy_score(test.drop(labels = ['text'], axis=1),predictions))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy =  0.2056451612903226\n\n\n"
     ]
    }
   ],
   "source": [
    "# using Label Powerset\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "# initialize label powerset multi-label classifier\n",
    "classifier = LabelPowerset(LogisticRegression())\n",
    "# train\n",
    "# Training logistic regression model on train data\n",
    "classifier.fit(xtrain_tfidf, train.drop(labels = ['text'], axis=1))\n",
    "# predict\n",
    "predictions = classifier.predict(xvalid_tfidf)\n",
    "# accuracy\n",
    "print(\"Accuracy = \",accuracy_score(test.drop(labels = ['text'], axis=1),predictions))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy =  0.13709677419354838\n\n\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.adapt import MLkNN\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "classifier_new = MLkNN(k=10)\n",
    "# Note that this classifier can throw up errors when handling sparse matrices.\n",
    "x_train = lil_matrix(xtrain_tfidf).toarray()\n",
    "y_train = lil_matrix(train.drop(labels = ['text'], axis=1)).toarray()\n",
    "x_test = lil_matrix(xvalid_tfidf).toarray()\n",
    "# train\n",
    "classifier_new.fit(x_train, y_train)\n",
    "# predict\n",
    "predictions_new = classifier_new.predict(x_test)\n",
    "# accuracy\n",
    "print(\"Accuracy = \",accuracy_score(test.drop(labels = ['text'], axis=1),predictions_new))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "neutral\n",
      "===========================================================\n",
      "people, many, way, think, local, need, problem, new, made, problems, say, policy, see, give, much, years, members, government, small, said, scheme, want, young, take, matter, view, point, present, difficulties, full\n",
      "===========================================================\n",
      "irrationality\n",
      "===========================================================\n",
      "mad, gone mad, bureaucracy gone, gone, patients, bus, put, decision, tribunals, stupid, passing, general, stansted affair, stansted, affair, hour, service, dentists, estates, seems, run, treatment, better, board, prepared, necessary table, wild, feel, expected, table\n",
      "===========================================================\n",
      "cost\n",
      "===========================================================\n",
      "money, cost, local, expenditure, time, public, people, new, government, authorities, public expenditure, less, members, point, local authorities, training, means, costs, made, come, expensive, many, spending, expense, present, authority, decision, know, local government, great\n",
      "===========================================================\n",
      "power\n",
      "===========================================================\n",
      "industry, general, control, power, feel, local, believe, people, rule, authorities, heavy, burden, new, words, controls, powerful, government, made, whole, proposals, number, sense, attempt, important, trust, said, time, aid, water, done\n",
      "===========================================================\n",
      "freedom\n",
      "===========================================================\n",
      "people, individual, feel, society, made, want, said, part, many, decision, whole, hand, tax, point, make, control, last, country, weight, local, question, members, know, freedom, wealth, companies, work, benefit, power, public\n",
      "===========================================================\n",
      "accountability\n",
      "===========================================================\n",
      "people, democracy, democratic, elected, local, decisions, government, control, parliamentary, new, means, entry, accountability, present, members, debate, many, world, result, system, political, set, industry, powers, european, problems, whole, authorities, anti, unrepresentative\n",
      "===========================================================\n",
      "centralisation\n",
      "===========================================================\n",
      "nationalisation, local, regional, centralised, nationalised, central, centralised bureaucracy, government, local government, ownership, plan, nationalised industries, growth, believe, industry, made, speech, industries, centre, public ownership, country, misleading, facts, public, centralisation, matter, authorities, central bureaucracy, enormous, learned\n",
      "===========================================================\n",
      "inefficiency\n",
      "===========================================================\n",
      "time, unnecessary, local, people, industry, red tape, work, tape, red, way, efficiency, effective, system, make, many, new, say, hope, authority, point, authorities, concerned, taken, made, administration, government, waste, paper, said, public\n",
      "===========================================================\n",
      "size\n",
      "===========================================================\n",
      "local, government, people, growth, increase, public, local government, staff, authority, members, authorities, great, say, make, growth bureaucracy, system, council, see, time, many, need, said, want, new, industry, increase bureaucracy, policy, services, country, tax\n",
      "===========================================================\n"
     ]
    }
   ],
   "source": [
    "for category in categories:\n",
    "\n",
    "    vectorizer = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,2), max_features=7500,max_df=0.3,stop_words=stops)\n",
    "    classifier = MultinomialNB()\n",
    "    vectorizer.fit(dfr['text'])\n",
    "    train = vectorizer.transform(dfr['text'])\n",
    "    classifier.fit(train,dfr[category])\n",
    "\n",
    "    ## Feature Selection\n",
    "    n = 30\n",
    "    class_labels = classifier.classes_\n",
    "    feature_names =vectorizer.get_feature_names()\n",
    "\n",
    "    topn_class1 = sorted(zip(classifier.feature_count_[0], feature_names),reverse=True)[:n]\n",
    "    topn_class2 = sorted(zip(classifier.feature_count_[1], feature_names),reverse=True)[:n]\n",
    "    print(category)\n",
    "    print(\"===========================================================\")\n",
    "    print(\", \".join([x[1] for x in topn_class2]))\n",
    "    print(\"===========================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "money, cost, local, expenditure, time, public, people, new, government, authorities, public expenditure, less, members, point, local authorities, training, means, costs, made, come, expensive, many, spending, expense, present, authority, decision, know, local government, great, said, years, civil, want, civil servants, speech, year, servants, set, staff, provide, say, case, wrong, country, let, make, spent, authors, cost bureaucracy\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}