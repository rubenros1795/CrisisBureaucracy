{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split, RandomizedSearchCV,cross_val_score,cross_validate  \n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report,f1_score,roc_auc_score,average_precision_score,average_precision_score,recall_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import re, string,os\n",
    "from glob import glob as gb\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from utils.functions import *\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import operator\n",
    "\n",
    "plotting.style()\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "project_path = '/home/ruben/Documents/GitHub/CrisisBureaucracy'\n",
    "data_path = '/media/ruben/Elements/PhD/data/hansard'\n",
    "\n",
    "m = KeyedVectors.load_word2vec_format('/media/ruben/Elements/PhD/casebureaucracy/w2v-models/model-single-sample.bin', binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 4080/4080 [00:53<00:00, 76.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load all sentences with 'bureaucracy' (not just annotated set, but everything: 4080 texts)\n",
    "df = pd.read_csv('~/Documents/GitHub/CrisisBureaucracy/data/classifier/bureaucracy-sentences-full.tsv',sep='\\t').dropna()\n",
    "\n",
    "def load_full(id_):\n",
    "    f = pd.read_csv(f'{data_path}/lemmatized_pm/uk.proc.d.{id_[:10]}.txt',sep='\\t')\n",
    "    return [list(f[f['id'] == 'uk.proc.d.' + id_]['text'])[0],list(f[f['id'] == 'uk.proc.d.' + id_]['text_lemmatized'])[0]]\n",
    "\n",
    "    \n",
    "df['text'] = [load_full(\"-\".join(x.split('-')[1:-1]))[0] for x in tqdm(df['id'])]\n",
    "df = df[['id','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 4080/4080 [00:59<00:00, 68.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# Split metadata to columns\n",
    "df['year'] = [int(x.split('-')[1]) for x in df.id]\n",
    "df['party'] = [str(x.split('-')[-1]) for x in df.id]\n",
    "df['id'] = [\"-\".join(x.split('-')[1:-1]) for x in df.id]\n",
    "\n",
    "# Clean\n",
    "stops = stopwords.words('english') + \"hon member friend gentleman gentlemen speaker right\".split(' ')\n",
    "df['text'] = [\" \".join([w.text for w in nlp(t) if w.pos_ in [\"ADJ\",\"NOUN\"] and str(w.text) not in stops]) for t in tqdm(df['text'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['party'].isin(['labour','conservative'])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Period:  1957 1963 | 204 texts\n",
      "Accuracy:  0.561\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "conservative       0.25      0.06      0.10        32\n",
      "      labour       0.59      0.88      0.71        50\n",
      "\n",
      "    accuracy                           0.56        82\n",
      "   macro avg       0.42      0.47      0.40        82\n",
      "weighted avg       0.46      0.56      0.47        82\n",
      "\n",
      "Counted predictions:  {'labour': 74, 'conservative': 8}\n",
      "======================================================\n",
      "Period:  1964 1970 | 518 texts\n",
      "Accuracy:  0.635\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "conservative       0.63      0.97      0.77       129\n",
      "      labour       0.64      0.09      0.16        79\n",
      "\n",
      "    accuracy                           0.63       208\n",
      "   macro avg       0.64      0.53      0.46       208\n",
      "weighted avg       0.64      0.63      0.53       208\n",
      "\n",
      "Counted predictions:  {'conservative': 197, 'labour': 11}\n",
      "======================================================\n",
      "Period:  1971 1973 | 254 texts\n",
      "Accuracy:  0.598\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "conservative       0.59      0.60      0.59        50\n",
      "      labour       0.61      0.60      0.60        52\n",
      "\n",
      "    accuracy                           0.60       102\n",
      "   macro avg       0.60      0.60      0.60       102\n",
      "weighted avg       0.60      0.60      0.60       102\n",
      "\n",
      "Counted predictions:  {'labour': 51, 'conservative': 51}\n",
      "======================================================\n",
      "Period:  1974 1979 | 1462 texts\n",
      "Accuracy:  0.662\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "conservative       0.67      0.90      0.77       365\n",
      "      labour       0.62      0.26      0.37       220\n",
      "\n",
      "    accuracy                           0.66       585\n",
      "   macro avg       0.64      0.58      0.57       585\n",
      "weighted avg       0.65      0.66      0.62       585\n",
      "\n",
      "Counted predictions:  {'conservative': 493, 'labour': 92}\n",
      "======================================================\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier for every government period\n",
    "\n",
    "for p in [[1957,1963],[1964,1970],[1971,1973],[1974,1979]]:\n",
    "    tdf = df[df['year'].isin(list(range(p[0],p[1]+1)))]\n",
    "        \n",
    "    ## Classifier\n",
    "    # vectorizer = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,3),stop_words=stops,smooth_idf=True)\n",
    "    vectorizer = CountVectorizer(analyzer='word',ngram_range=(1,3),stop_words=(1,3))\n",
    "    X = vectorizer.fit_transform(tdf['text']).toarray()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, tdf['party'], test_size = 0.4,random_state = 0)\n",
    "    # classifier = svm.LinearSVC()\n",
    "    # classifier = MultinomialNB()\n",
    "    classifier = LogisticRegression()\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Classification metrics\n",
    "    print(\"Period: \",p[0],p[1],'|',len(tdf),'texts')\n",
    "    print('Accuracy: ', round(accuracy_score(y_test, y_pred),3))\n",
    "    print('\\n', classification_report(y_test,y_pred))\n",
    "    print(\"Counted predictions: \",dict(Counter(y_pred)))\n",
    "    print('======================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract important words for every period\n",
    "# Important here means features (words) with a coefficient of > 0.5\n",
    "\n",
    "def important_words_period(start_year,end_year,verbose=False,n=50):\n",
    "    tdf = df[df['year'].isin(list(range(start_year,end_year+1)))]\n",
    "    \n",
    "    ## Classifier\n",
    "    vectorizer = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,2), max_features=7500,max_df=0.3,stop_words=stops)\n",
    "    classifier = MultinomialNB()\n",
    "    vectorizer.fit(tdf['text'])\n",
    "    train = vectorizer.transform(tdf['text'])\n",
    "    classifier.fit(train,tdf['party'])\n",
    "    \n",
    "    ## Feature Selection\n",
    "    class_labels = classifier.classes_\n",
    "    feature_names =vectorizer.get_feature_names()\n",
    "\n",
    "    topn_class1 = sorted(zip(classifier.feature_count_[0], feature_names),reverse=True)[:n]\n",
    "    topn_class2 = sorted(zip(classifier.feature_count_[1], feature_names),reverse=True)[:n]\n",
    "\n",
    "    if verbose == True:\n",
    "        print(\"Important words in class: conservative\")\n",
    "        for coef, feat in topn_class1:\n",
    "            print('\\t',feat,'\\t',round(coef,3))\n",
    "        print(\"-----------------------------------------\")\n",
    "        print(\"Important words in class: labour\")\n",
    "        for coef, feat in topn_class2:\n",
    "            print('\\t',feat,'\\t',round(coef,3))\n",
    "    return topn_class1, topn_class2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for p in [[1957,1963],[1964,1970],[1971,1973],[1974,1976],[1977,1980]]:\n",
    "    w_con,w_lab = words_period(p[0],p[1]+1,False,150)\n",
    "    words += [w[1] for w in w_con if w[0] > 0.5]\n",
    "    words += [w[1] for w in w_lab if w[0] > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(list(set(words))).to_csv(project_path + '/data/classifier/party-classification-words.csv',index=False)"
   ]
  }
 ]
}